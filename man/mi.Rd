% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mi.R
\name{mi}
\alias{mi}
\title{Mutual Information}
\usage{
mi(x, y)
}
\arguments{
\item{x, y}{numeric or discrete data vectors}
}
\description{
Estimates Kullback-Leibler divergence of joint distribution and the product of two respective marginal distributions. Roughly speaking, the amount of information one variable provides about another.
}
\examples{
# Sample data
a <- rnorm(25, 80, 35)
b <- rnorm(25, 100, 50)

mlf::mi(a, b)
}
